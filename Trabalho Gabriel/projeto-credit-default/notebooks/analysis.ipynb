{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc51ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # An√°lise de Inadimpl√™ncia em Cart√£o de Cr√©dito\n",
    "# ## 1. Informa√ß√µes B√°sicas\n",
    "# \n",
    "# ‚Ä¢ Nome do dataset: Default of Credit Card Clients  \n",
    "# ‚Ä¢ Fonte: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)  \n",
    "# ‚Ä¢ Dimens√µes: 30.000 linhas √ó 25 colunas  \n",
    "# ‚Ä¢ Tamanho em MB: ~3.7 MB  \n",
    "\n",
    "# %%\n",
    "# Importa√ß√£o de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√£o de estilo\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# %%\n",
    "# Carregar os dados\n",
    "df = pd.read_excel('../data/default_of_credit_card_clients.xls', header=1)\n",
    "\n",
    "# Verificar dimens√µes iniciais\n",
    "print(\"=== INFORMA√á√ïES INICIAIS ===\")\n",
    "print(f\"Dimens√µes do dataset: {df.shape}\")\n",
    "print(f\"Tamanho aproximado em MB: {round(df.memory_usage(deep=True).sum() / (1024**2), 2)}\")\n",
    "\n",
    "# %%\n",
    "# Visualizar as primeiras linhas\n",
    "print(\"\\nPrimeiras 5 linhas do dataset:\")\n",
    "df.head()\n",
    "\n",
    "# %%\n",
    "# Informa√ß√µes sobre colunas e tipos de dados\n",
    "print(\"\\nInforma√ß√µes sobre colunas e tipos de dados:\")\n",
    "df.info()\n",
    "\n",
    "# ## üéØ VALIDA√á√ÉO DAS INFORMA√á√ïES\n",
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# VALIDA√á√ÉO COMPLETA DOS DADOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=== VALIDA√á√ÉO DOS DADOS ===\\n\")\n",
    "\n",
    "# 1. Dimens√µes confirmadas\n",
    "print(f\"1. Dimens√µes confirmadas: {df.shape}\")\n",
    "\n",
    "# 2. Tamanho em MB\n",
    "size_mb = round(df.memory_usage(deep=True).sum() / (1024**2), 2)\n",
    "print(f\"2. Tamanho em MB: {size_mb} MB\")\n",
    "\n",
    "# 3. Renomear coluna target\n",
    "df.rename(columns={'default payment next month': 'inadimplente'}, inplace=True)\n",
    "print(\"3. Coluna target renomeada para 'inadimplente'\")\n",
    "\n",
    "# 4. Distribui√ß√£o do target\n",
    "target_dist = df['inadimplente'].value_counts()\n",
    "print(f\"4. Distribui√ß√£o do target:\")\n",
    "print(f\"   - Classe 0 (N√£o inadimplente): {target_dist[0]} ({target_dist[0]/len(df)*100:.2f}%)\")\n",
    "print(f\"   - Classe 1 (Inadimplente): {target_dist[1]} ({target_dist[1]/len(df)*100:.2f}%)\")\n",
    "\n",
    "# 5. Valores nulos\n",
    "null_count = df.isnull().sum().sum()\n",
    "print(f\"5. Valores nulos totais: {null_count}\")\n",
    "print(f\"   - Dataset completo: {null_count == 0}\")\n",
    "\n",
    "# 6. Tipos de dados\n",
    "print(\"6. Tipos de dados presentes:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# 7. Duplicatas\n",
    "duplicatas = df.duplicated().sum()\n",
    "print(f\"7. Linhas duplicadas: {duplicatas}\")\n",
    "\n",
    "# 8. Estat√≠sticas b√°sicas\n",
    "print(\"\\n8. Estat√≠sticas descritivas b√°sicas:\")\n",
    "print(df.describe())\n",
    "\n",
    "# ## 2. Problema de Machine Learning\n",
    "# \n",
    "# ‚Ä¢ Tipo: [X] Classifica√ß√£o [ ] Regress√£o  \n",
    "# ‚Ä¢ Vari√°vel alvo (target): `inadimplente`  \n",
    "# ‚Ä¢ N√∫mero de classes: 2 (0 = N√£o inadimplente, 1 = Inadimplente)  \n",
    "# ‚Ä¢ Distribui√ß√£o do target:  \n",
    "#   - Classe 0: 23.364 casos (77,88%)  \n",
    "#   - Classe 1: 6.636 casos (22,12%)  \n",
    "#   - Dataset apresenta desbalanceamento moderado\n",
    "\n",
    "# ## 3. Qualidade dos Dados\n",
    "# \n",
    "# ‚Ä¢ % valores faltantes: 0% (dataset completo)  \n",
    "# ‚Ä¢ Tipos de vari√°veis: \n",
    "#   - Num√©ricas cont√≠nuas: LIMIT_BAL, BILL_AMT1 at√© BILL_AMT6, PAY_AMT1 at√© PAY_AMT6  \n",
    "#   - Categ√≥ricas: SEX, EDUCATION, MARRIAGE, PAY_0 at√© PAY_6  \n",
    "#   - Datas: Nenhuma  \n",
    "#   - Texto: Nenhuma  \n",
    "# ‚Ä¢ Qualidade geral: Excelente - dados completos e estruturados\n",
    "\n",
    "# ## 4. Justificativa\n",
    "# \n",
    "# ‚Ä¢ Por que escolhemos este dataset? \n",
    "#   Dataset cl√°ssico e bem-estruturado para aprendizado de classifica√ß√£o bin√°ria, com aplica√ß√£o pr√°tica real no setor financeiro. Ideal para aprendizado dos fundamentos de ML.\n",
    "# \n",
    "# ‚Ä¢ Qual problema real queremos resolver?\n",
    "#   Prever a inadimpl√™ncia de clientes com anteced√™ncia, permitindo que institui√ß√µes financeiras reduzam perdas, otimizem a gest√£o de risco de cr√©dito e criem estrat√©gias de reten√ß√£o proativas.\n",
    "# \n",
    "# ‚Ä¢ Que insights esperamos encontrar?\n",
    "#   Identificar os principais fatores preditivos de inadimpl√™ncia (hist√≥rico de pagamentos, limite de cr√©dito, demografia), entender padr√µes de comportamento e construir um modelo com boa capacidade preditiva.\n",
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# AN√ÅLISE EXPLORAT√ìRIA DE DADOS (EDA)\n",
    "# =============================================================================\n",
    "\n",
    "# ## 5. An√°lise Explorat√≥ria (EDA)\n",
    "\n",
    "# %%\n",
    "# Distribui√ß√£o da vari√°vel target\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='inadimplente', data=df)\n",
    "plt.title('Distribui√ß√£o de Inadimplentes')\n",
    "plt.xlabel('Inadimplente (0 = N√£o, 1 = Sim)')\n",
    "plt.ylabel('Contagem')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(target_dist.values, labels=['N√£o Inadimplente', 'Inadimplente'], \n",
    "        autopct='%1.1f%%', colors=['lightblue', 'lightcoral'])\n",
    "plt.title('Propor√ß√£o de Inadimpl√™ncia')\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# An√°lise de correla√ß√µes (apenas com algumas vari√°veis para performance)\n",
    "print(\"Correla√ß√£o com a vari√°vel target (inadimplente):\")\n",
    "correlation_with_target = df.corr()['inadimplente'].sort_values(ascending=False)\n",
    "print(correlation_with_target.head(10))\n",
    "\n",
    "# Heatmap de correla√ß√£o das vari√°veis mais relevantes\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = correlation_with_target.abs().sort_values(ascending=False).head(10).index\n",
    "sns.heatmap(df[top_features].corr(), annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Matriz de Correla√ß√£o - Top 10 Features')\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# An√°lise de algumas vari√°veis importantes\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# LIMIT_BAL por inadimpl√™ncia\n",
    "sns.boxplot(x='inadimplente', y='LIMIT_BAL', data=df, ax=axes[0,0])\n",
    "axes[0,0].set_title('Limite de Cr√©dito vs Inadimpl√™ncia')\n",
    "axes[0,0].set_xlabel('Inadimplente')\n",
    "axes[0,0].set_ylabel('Limite de Cr√©dito')\n",
    "\n",
    "# SEX (G√™nero) por inadimpl√™ncia\n",
    "sex_counts = pd.crosstab(df['SEX'], df['inadimplente'])\n",
    "sex_counts.plot(kind='bar', ax=axes[0,1])\n",
    "axes[0,1].set_title('Inadimpl√™ncia por G√™nero')\n",
    "axes[0,1].set_xlabel('G√™nero (1=M, 2=F)')\n",
    "axes[0,1].set_ylabel('Contagem')\n",
    "\n",
    "# EDUCATION por inadimpl√™ncia\n",
    "edu_counts = pd.crosstab(df['EDUCATION'], df['inadimplente'])\n",
    "edu_counts.plot(kind='bar', ax=axes[1,0])\n",
    "axes[1,0].set_title('Inadimpl√™ncia por Educa√ß√£o')\n",
    "axes[1,0].set_xlabel('N√≠vel Educacional')\n",
    "axes[1,0].set_ylabel('Contagem')\n",
    "\n",
    "# AGE por inadimpl√™ncia\n",
    "sns.histplot(data=df, x='AGE', hue='inadimplente', bins=30, ax=axes[1,1])\n",
    "axes[1,1].set_title('Distribui√ß√£o de Idade por Inadimpl√™ncia')\n",
    "axes[1,1].set_xlabel('Idade')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ## 6. Prepara√ß√£o para Machine Learning\n",
    "\n",
    "# %%\n",
    "# Separar features e target\n",
    "X = df.drop('inadimplente', axis=1)\n",
    "y = df['inadimplente']\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Shape do X_train: {X_train.shape}\")\n",
    "print(f\"Shape do X_test: {X_test.shape}\")\n",
    "print(f\"Propor√ß√£o no treino: {y_train.value_counts(normalize=True).values}\")\n",
    "print(f\"Propor√ß√£o no teste: {y_test.value_counts(normalize=True).values}\")\n",
    "\n",
    "# %%\n",
    "# Modelo 1: Random Forest\n",
    "print(\"=== RANDOM FOREST ===\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Relat√≥rio de Classifica√ß√£o:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(f\"Acur√°cia: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1]):.4f}\")\n",
    "\n",
    "# %%\n",
    "# Modelo 2: Regress√£o Log√≠stica\n",
    "print(\"=== REGRESS√ÉO LOG√çSTICA ===\")\n",
    "lr_model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "print(\"Relat√≥rio de Classifica√ß√£o:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(f\"Acur√°cia: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, lr_model.predict_proba(X_test)[:, 1]):.4f}\")\n",
    "\n",
    "# %%\n",
    "# Matriz de Confus√£o - Random Forest\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confus√£o - Random Forest')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.xlabel('Previsto')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Reds')\n",
    "plt.title('Matriz de Confus√£o - Regress√£o Log√≠stica')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.xlabel('Previsto')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Import√¢ncia das features - Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance.head(15))\n",
    "plt.title('Top 15 Features Mais Importantes - Random Forest')\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 features mais importantes:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# ## 7. Conclus√µes e Pr√≥ximos Passos\n",
    "# \n",
    "# Principais Insights:\n",
    "# - Dataset bem balanceado para um problema de cr√©dito (22% inadimpl√™ncia)\n",
    "# - Vari√°veis de hist√≥rico de pagamento (PAY_0 a PAY_6) s√£o as mais importantes\n",
    "# - Random Forest performou melhor que Regress√£o Log√≠stica\n",
    "# - Modelo conseguiu capturar padr√µes preditivos relevantes\n",
    "# \n",
    "# Pr√≥ximos Passos Sugeridos:\n",
    "# 1. Tratamento de desbalanceamento (SMOTE, undersampling)\n",
    "# 2. Engenharia de features mais avan√ßada\n",
    "# 3. Otimiza√ß√£o de hiperpar√¢metros\n",
    "# 4. Teste com outros modelos (XGBoost, LightGBM)\n",
    "# 5. Valida√ß√£o cruzada mais robusta\n",
    "\n",
    "# %%\n",
    "# Salvar resultados finais\n",
    "results = {\n",
    "    'modelo': ['Random Forest', 'Regress√£o Log√≠stica'],\n",
    "    'acuracia': [\n",
    "        accuracy_score(y_test, y_pred_rf),\n",
    "        accuracy_score(y_test, y_pred_lr)\n",
    "    ],\n",
    "    'roc_auc': [\n",
    "        roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1]),\n",
    "        roc_auc_score(y_test, lr_model.predict_proba(X_test)[:, 1])\n",
    "    ]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"=== RESULTADOS FINAIS ===\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05fa56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
